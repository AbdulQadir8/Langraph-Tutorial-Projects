{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAskYZ0+fR6p5Q6o4Tfu11",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdulQadir8/Langraph-Tutorial-Projects/blob/master/langraph_tutorial_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oiivz0awra6z"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")"
      ],
      "metadata": {
        "id": "ipLj82yktpjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model='gemini-1.5-flash',\n",
        "    max_retries=2,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "llm.invoke('greet me')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1JhMJplt-ZU",
        "outputId": "24ddfc10-1355-4dee-8553-c3847a423608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello there! How can I help you today? \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-4f21032d-c2c1-45c2-a19b-41f1891b6cf8-0', usage_metadata={'input_tokens': 3, 'output_tokens': 10, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Build a Basic Chatbot\n",
        "\n",
        "We'll first create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Though simple, it will illustrate the core concepts of building with LangGraph. By the end of this section, you will have a built rudimentary chatbot.\n",
        "\n",
        "Start by creating a `StateGraph`. A `StateGraph` object defines the structure of our chatbot as a \"state machine\". We'll add `nodes` to represent the llm and functions our chatbot can call and `edges` to specify how the bot should transition between these functions."
      ],
      "metadata": {
        "id": "w_hI-vtlvLRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "  # Messages have the type \"list\". The `add_messages` function\n",
        "  # in the annotation defines how this state key should be updated\n",
        "  # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "  messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "J2RBbHbLutup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage of add_messages\n",
        "new_messages_1 = [{\"role\": \"user\", \"content\": \"Hello\"}]\n",
        "new_messages_2 = [{\"role\": \"ai\", \"content\": \"Hi there!\"}]\n",
        "\n",
        "updated_state_1 = add_messages(new_messages_1, new_messages_2)\n",
        "\n",
        "\n",
        "print(\"Updated State 1:\", updated_state_1)\n",
        "\n",
        "# from typing import Annotated\n",
        "# from typing_extensions import TypedDict\n",
        "# from langgraph.graph import StateGraph\n",
        "\n",
        "# class State(TypedDict):\n",
        "#     messages: Annotated[list, add_messages]\n",
        "\n",
        "# builder = StateGraph(State)\n",
        "# builder.add_node(\"chatbot\", lambda state: {\"messages\": [(\"assistant\", \"Hello\")]})\n",
        "# builder.set_entry_point(\"chatbot\")\n",
        "# builder.set_finish_point(\"chatbot\")\n",
        "# graph = builder.compile()\n",
        "# graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PdOc5W0xs-l",
        "outputId": "33bbe467-be2e-495d-b934-071c44033273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated State 1: [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='6858c1cb-286c-4ba4-a71b-f8d50a7cfeb9'), AIMessage(content='Hi there!', additional_kwargs={}, response_metadata={}, id='367dfa8d-dc7d-4fee-9fdd-5d9f28844330')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now our graph knows two things:\n",
        "\n",
        "1. Every `node` we define will receive the current `State` as input and return a value that updates that state.\n",
        "2. `messages` will be _appended_ to the current list, rather than directly overwritten. This is communicated via the prebuilt [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) function in the `Annotated` syntax.\n",
        "\n",
        "Next, add a \"`chatbot`\" node. Nodes represent units of work. They are typically regular python functions."
      ],
      "metadata": {
        "id": "qWDmHwi_jrRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state: State):\n",
        "  return {\"messages\":[llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "# The first argument is the unique node name\n",
        "# The second argument is the function or object that will be called whenever\n",
        "# the node is used.\n",
        "graph_builder.add_node(\"chatbot\",chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCs0zITnajk0",
        "outputId": "77df7f16-f454-4fe1-868d-4f1989355569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d9047fb4d30>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notice** how the `chatbot` node function takes the current `State` as input and returns a dictionary containing an updated `messages` list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\n",
        "\n",
        "The `add_messages` function in our `State` will append the llm's response messages to whatever messages are already in the state.\n",
        "\n",
        "Next, add an `entry` point. This tells our graph **where to start its work** each time we run it."
      ],
      "metadata": {
        "id": "A0dXMxRSwydc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START, \"chatbot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xSESPa6k3Nm",
        "outputId": "f971366c-a482-42f2-b5a9-086b05ca2ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d9047fb4d30>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, set a `finish` point. This instructs the graph **\"any time this node\n",
        "is run, you can exit.\"**"
      ],
      "metadata": {
        "id": "tqI1GFpKxME3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(\"chatbot\", END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnDGF9b-w-zN",
        "outputId": "5f613b15-5fc6-4ca9-950a-c54849be1b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d9047fb4d30>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yokptS0pzV8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "-kjfW7sKxxJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can visualize the graph using the `get_graph` method and one of the \"draw\"\n",
        "\n",
        "---\n",
        "\n",
        "methods, like `draw_ascii` or `draw_png`. The `draw` methods each require additional dependencies."
      ],
      "metadata": {
        "id": "XhTPsvSSzZ0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except:\n",
        "  # This requires some extra dependencies and is optional\n",
        "  pass\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "ND-mhP7wzCOs",
        "outputId": "c587ce93-1b59-4f1a-edda-ced587142d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCADqAGsDASIAAhEBAxEB/8QAHQABAAMBAAMBAQAAAAAAAAAAAAUGBwQCAwgBCf/EAE0QAAEDAwEDBQkKDAQHAAAAAAECAwQABREGBxIhExUxQZQIFiJRVmGB0dMUFyMyNlRVcXSVJTVCUlNzkZKTsrO0YnKD0iRDREaxwfD/xAAaAQEBAAMBAQAAAAAAAAAAAAAAAQIDBAUH/8QAMxEAAgECAgcFCAIDAAAAAAAAAAECAxEEMRIUIVFxkaFBUmHB0RMjMjNTYoGSIkLh8PH/2gAMAwEAAhEDEQA/AP6p0pUFdrtLk3AWi0hIlhIXJmODebiIPRw/KcV+SnoABUrhupXnGLm7IuZMvyGozZcecQ0gdKlqCQPSajzqmyg4N3gA/aUeuuBnZ/ZSsPXCKL3MxhUq6gPrPHPAEbqPqQlI81dw0rZQMczwMfZUeqttqKzbY2H731WX6YgdpR66d9Vl+mIHaUeunerZfoeB2ZHqp3q2X6HgdmR6qe58ehdg76rL9MQO0o9dO+qy/TEDtKPXTvVsv0PA7Mj1U71bL9DwOzI9VPc+PQbB31WX6YgdpR66d9Vl+mIHaUeunerZfoeB2ZHqp3q2X6HgdmR6qe58eg2HTDu0G4EiLMjySOpl1K//AAa66gpmhNOTx8NY7epXU4mMhK0+dKgAQfODXG6iZosF9L8m6WMH4Zp9XKPw0/noV8ZxA6SlRUoDJBOAmmhCeyD27n6/8JZPItNK8W3EPNpcbUlaFAKSpJyCD0EGvKuch65D6IzDjzhwhtJWo+IAZNQGz9lR0xFuDwHuy6jnGQoZ4rcAIHH81O4geZAqauUT3fbpUXOOXaW3nxZBH/uorQUr3XouyrIKXERG2nEqGClxA3FpI8ykkeiuhbKLtvXmXsJ6lKVzkK7rraDp/ZrYxd9SXAW6Cp5EZtQaW6466s4Q2222lS1qODhKQTwPirN9Zd1NpnTE7Z+qMzPudp1VIlNmZHtkxbkdDLbpUQyhhS1L5RsIKMBQG8ojCSam+6FtNou2iIgu9q1LcBHuTEmJJ0lHU9cLdIQFFEptKcnweIOEq+PgpIJrIzO2gu6e2P631bp69XiTp7UM8zWods/Ca4LseTHjyXYjeSlZC2ytCRkb2cDiABs+s+6C0Fs9uceBqG+Ltkh6O3K+EgSVNstLJCFvLS2UsgkEZcKeg+KvfqfbnorR+pkaduV3d58ciNTm4EOBJluuMOLWhLiUstr3k5bVkj4uAVYBBOC7cxqvaBcda22XaNev2q56caRpS12Jl6NFdeejr5bnBaSkJWlwpSWn1BO4DhKiTVw2KafuidrsC9TbJcYTHvb2aB7pnQnGdyQl98usEqSMOJ8AqR0jwT1igLhst7oK1bTNbav001BnwplkujsFlbkCUGn222mlKcU6plLbat5xQDZVvEJChkKBrV6w/ZPIuGi9r+0jT1z09eko1BqBV6t94agrcty2FQmEkKkAbqFhTCk7qsEkpxnNbhQClKUBWNDYgtXWyJwGrRMMaOlOcJYU2h1pIz1JS4EDzIqz1WdJJ90XrVM9OeSeuAZbJGMhplttR8/hhweirNXRX+Y3wvxtt6leYqrvBWjblKlhtS7FNcL0jk0lSobxxvOED/lKxlRHxFZUcpUpSLRStcJ6N09qYKrqjZ7ozagxAk6g0/ZtUMsJUqI7OityUoSvG8UFQOArdTnHTgVAjubdlASU+9vpbdJBI5pYwT1fk+c1ZZOgrW4+4/DVLs7zhJWq2SVsJUScklsHcJJ45Kc9PHia9XeTI6tU34f6zPsq2aFJ5StxXpcbDw0hso0Xs/mPy9M6Us9glPt8k69bYTbC1ozndJSBkZAOKtdVfvJkeVV+/jM+yp3kyPKq/fxmfZU9nT7/AEYst5aKVlmsbddbHqbQsCLqm8GPebu7Cl8q6zvcmmBLfG58GPC32G/Hw3uHWLX3kyPKq/fxmfZU9nT7/Riy3kvqDTtr1XZ5NpvVujXW2SQA9DmNJdacAIUApKgQcEA/WBVJR3N2ylsko2caXSSCMi0sDgRgj4viNT/eTI8qr9/GZ9lTvJkeVV+/jM+yp7On3+jFlvIm0bAdmlgukW5W3QOnIFwiuJeYlRrYyhxpYOQpKgnIIPWKnrtf3JMly02Rbci653XXfjNQUnpW7/ix8VvpUcdCd5Sec6CZkcJt5vU9s8C05OU0lX18luZHm6D11PW62RLRERFhRmokdOSG2UBIyek8Os9Z66e7htT0n0GxHhZrTHsVqi2+KFBiOgISVneUrxqUetROST1kk120pWhtyd3mQUpSoBSlKAUpSgM/2kFI1zsp3iQTqKRu4HSeaLh5x1Z8f1dY0Cs/2kZ7+NlOCnHfDIzvAZ/FFw6M8c/VxxnqzWgUApSlAKUpQClKUApSlAKUpQClKUBnu0oA662T5UlONRyMBQ4q/BFx4Dh09fV0H6q0Ks92l47+tk2SQe+ORjwc5/A9x/Z/9460KgFKUoBSlKAUpSgFKVXL9qiRFn822mG3PuCUJdeL7xaZYQokJ3lBKiVHBwkDoGSU5GdkISqO0S5ljpVI591h8wsfa3vZ0591h8wsfa3vZ10arPeuaFi70qkc+6w+YWPtb3s6c+6w+YWPtb3s6arPeuaFj5R7pru3JmybbVaNPXTZ2685pq5KuMaQ3dRu3Bl2HIYQpILB3D/xGTgnBQpOTxNfZ2kL1I1JpOyXaZb12mXPgsSnoDi99UZa20qU0VYGSkkpzgZx0CsA2x9z+9tr11ovVF7t9mTM03I5QtokOKTNaB30suZa+KFje4fnKHXka/z7rD5hY+1vezpqs965oWLvSqRz7rD5hY+1vezpz7rD5hY+1vezpqs965oWLvSqRz7rD5hY+1vezr9Gr75aQZF5tkHm1HF5+3yXHHGU/nltTY3kjpODkAcAropqtTss/wAoWLtSvFC0uIStCgpKhkKByCK8q4yCqHAOda6sz1Pxx6Pc6PWavlUKB8tdW/r4/wDbt124X+/DzRV2k1SlK3EFKh4+rrTK1XN001L3r1DiNTn4vJrG4y4paW1b2N05LaxgHIxxAyKmKgFK4Z18t9sm2+HLmsRpdwdUzEYdcCVyFpQpakoHSohKVKOOgA1y23V1pu+orzYokvlbrZwwZ0fk1p5EPJKmvCICVZCSfBJxjjigJilK4Zl8t9vuNvgSZrDE64KWiJGccAcfKEFa9xPSrdSCTjoFUHdXBqAA2G5AgEGM7wP+Q131wX/8RXL7M5/Kazh8SKsyb0goq0nZSTkmCwSf9NNS9Q+jvkjZPsLH9NNTFedV+ZLiw8xVCgfLXVv6+P8A27dX2qFA+Wurf18f+3browv9+Hmgu0mqwq5RbhtX276t0xO1Pe9PWXTVtgOxINinqguS3JAdUt9biMLUlHJpQE53c5yOPHdapWudjGjtpFyi3G/2f3TcYzRYbmxpT0V/kiclsuMrQpSM5O6okcTw41sauQyCfs2Vqvuh9TWvvq1HaxC0da0CZbLgY8h9wPS0pcdcQAVkYJxwSoqOQeGK7btaX7bLojZlbosnUcrWcvTfO85Vov5skVLe8GhIfdQ2tS1laTutpSU8VlQxivpOxbO9PaZupuVstqYkw26Pad9DqyBFYKiy2ElRSAnfVxAyc8ScCq3I7nbZ7JtVitytPlMSyRVQYSWpshtSY5OVMrWlwKdbJGShwqB8VY6LBgMQStsFn7me7aku11Tcp782NKl225PQ1rUiFJ+ECmlJ3VqLYypOCQpSegkVal7OhqzbVtj5PV2oNLuW6FaCzMtdyWwEqERwhx79KE7vELyCCrrOa12XsI0LM0bC0quwpRYYMtU6HFZkvNGI8VKUVMuJWFtcVrwEKAAUQBjhXBeu5r2c6hlKk3DT65Dy2WYzq+cZSeXaabS2227h0cqkJSBuryDxJySSZosGQbNNU6k7oa8aUt2or9eNORhoqLfHGrDMVAdnynn3GlPKW3hW4kNJIQPBy7xyMCq7ZWZG1q/bDntQX28vyhP1FaedLdc3oS5bcVLyG30qZUnC1pbG8pOCrBB4cK+mNYbF9Ga7atqLvZEK5tZMeGuE+7DWyyQAWkrYWhXJkJHgZ3eA4UvmxbRWodL2fTsuwsotFnUlduZhuuRVRFJSUgtuNKStPAkHB45Oc00WC6pTupCck4GMk5NcN/8AxFcvszn8prqiRW4MRmMyClllCW0AqKiEgYHE8TwHSa5b/wDiK5fZnP5TXRD4kVZk1o75I2T7Cx/TTUxUPo75I2T7Cx/TTUxXnVfmS4sPMVQoHy11b+vj/wBu3V9qo3yzXG3XqRdrXFFxRLShMmHyobcCkDCXEFR3Tw4FJI6AQeo78NJJyTeat1T8gjrpUJztfvIy69qhe3pztfvIy69qhe3rr0PuX7L1LYm6VCc7X7yMuvaoXt6c7X7yMuvaoXt6aH3L9l6ixN0qp3TW8+zT7RCmaUurUm7SVQ4SOXiK5V1LLj5TkPEJ+DZcVk4Hg46SAZHna/eRl17VC9vTQ+5fsvUWJulQnO1+8jLr2qF7enO1+8jLr2qF7emh9y/ZeosTdcF//EVy+zOfymuPna/eRl17VC9vXi9H1BqSO7bzZHrIxIQpp6ZMkMrU2gjBKEtLXlWDwyQB08cYOUYqLTclbivUWLRo75I2T7Cx/TTUxXqixm4UVmOyndaaQG0J8SQMAV7a8mb0pOW8xFKUrAClKUApSlAUHaKnOttlhxnGoJBzu5x+CZ/mOP2j6+ODfqz/AGkI3tc7KTuqO7qKQchOQPwRcBk8eHT08ekePNaBQClKUApSlAKUpQClKUApSlAKUpQGe7Sika62TZOCdRyMeCDk8z3H9n1+jrrQqoG0cLOuNlW6XABqGRvbgyCOabh8bxDOPTir/QClKUApSlAKUpQClKUApX4pQQkqUQlIGSScACq5J2laSiOqbe1PZ23EnCkGc1lP1je4VshTnU+BN8C2byLJSqr76ujfKqz9tb9dPfV0b5VWftrfrrZq1fuPky6L3FA2obVNERdoOzliRq+wMyLbqKT7racubCVRSLXPbPKArBR4Sgnwh0qAxk8Nigzo10hR5kOQ1LhyG0vMyGFhbbqFDKVJUOBBBBBHAg1/ODuztgVj2lbfNL3/AEpe7WYGpnkRr4+xJbKIS0YBkrwcBKmx6VIPWoZ+69N612f6T07a7HbdS2di3WyK1CjNe7mzuNNoCEDp6kpFNWr9x8mNF7i90qq++ro3yqs/bW/XX6NqmjSflVZh5zObA/mpq1fuPkyaL3FppXHbLxAvUfl7dNjT2P0sZ1Lif2pJFdlaGnF2ZBSlKgFRuo9QQ9LWeRcpylJYZA8FAytaicJQkdaiSAPrqSrGdud0XIv9ltIVhhhlyc4j85ZPJtn0Dlf3h4q7sFh9arxpPLt4IqKfqjUdx1tKW7dXD7kKiWrahZ5BtPVvDocV/iUOnOAkcKjkNpaSEoSEJHQEjAFftK+jwhGlFQgrJGDbYpSqDets9pssu4g2y8TbZbHCzPvEOIHIkVacb4UreCjuZ8IoSoJ454g1J1I01eTsQv1Kzy97bbVZp99jJtF5uTdjDblwlQYyFsstLZS6Hd4rG8ndVxCQVeCTu4wT3X7avbLRc4duhQLnqKdIiidyFmjh1TUc8EurKlJACuOBkqODgVh7ent25AutKpOxXUlw1dst09eLrIMq4S2Ct54tpRvHfUPipAA4AdAq7VshNVIqaye0HhHbMGYmZDccgzUkESYquTc+okdI8xyD1its2Z7RFaoQq2XLcRemG+U3kDdTJbBA5RI6iCUhQ6iQRwOBi1eyDdF2G9Wq6tq3FRJbSlHxtqUEOJ9KFK9OPFXDjsHDF0mmv5LJ+XAzTvsZ9RUpSvnAFYptxgLjars88hRZlRHIu91JWhW+kfWQtZH+Q1tdQesdKRtZWJ23SFFpWQ4w+lOVMup+KsDr8RHWCR116GAxCwuIjUll2/kqPnRa0tIUtaghCRlSlHAA8Zqqe+7oU/8AemnvvVj/AH1crxbpenLkbbdmRFlkkI4/BvpH5Tavyh5ukZwQK4/cMY/9O1+4K+h3c0pU2rP8+ZhaxWffd0L5a6d+9WP99ZZA2SqsuoL0xM2bWjWcW43R2dGvrzsdJbZeXvqQ6HAVkoJVgpCgoY6K3n3FH/QNfuCvdWqdD2tnUeXh63Blb2hLshe1xDEBKGL3EbZtaUuIAe3YAZ3QM+BhY3fCx4+jjUbp3TerdnmoGblC06L8xdLJbocxpE1pl2FIjNqTxKzhSCFnJSScjoPXs1Kjw0bqSbTV+rb3eLBlmy++WnZfs609p3Vt6tGn75FjEvQZtyYStGVqIPx+IPjFWf33dC+WunfvVj/fVocjMuq3ltIWrxqSCa8fcMb5u1+4KzjCcIqEWrLw/wAg47FqW0aojOSLNdYV2jtr5NbsGQh5KVYB3SUkgHBBx56km4C7vcLdbWgVOTZbLACekJ3wVn0IC1fUDXpKmIe4gBLZcUEobQnwlqPQEpHEnzCtg2V7PH7U+L9d2uSnqbLcaIrBMdCulSv8agB/lGR1qrRi8VHCUXOb/l2eL/3MyjvNMpSlfNgKUpQHJdLTBvcNcS4Q2J0VfxmZDYcQfQeFVB7Ylo91RULfJYz+SxcZLafQlLgA9Aq9UrfTxFajspza4Not2ig+8bpH5rP+9pftae8bpH5rP+9pftav1K369ivqy5sXZQfeN0j81n/e0v2tPeN0j81n/e0v2tX6lNexX1Zc2LsoPvG6R+az/vaX7Wv0bDtIA8Yk8jxG7S/a1faU17FfVlzYuyB09oPT+lXC7a7UxGfI3TIIK3iPEXFEqI9NT1KVyTnKo9Kbu/EmYpSlYA//2Q==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for event in graph.stream({\"messages\":[(\"user\",\"I am Abdul Qadir\")]}):\n",
        "  print(\"EVENT: \",list(event.values())[0][\"messages\"][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAVtRNEI0Yuw",
        "outputId": "bf70a4d4-681f-44e5-b22b-2660e5ed5e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVENT:  content=\"Hello Abdul Qadir, it's nice to meet you! \\n\\nIs there anything I can help you with today? I'm ready to answer questions, provide information, or just have a chat. \\n\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-c7df6fd9-1d47-43fc-b86a-5ea0edfd8c7b-0' usage_metadata={'input_tokens': 6, 'output_tokens': 42, 'total_tokens': 48, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "  for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
        "    for value in event.values():\n",
        "      print(\"Assistant\", value[\"messages\"][-1].content)\n",
        "\n",
        "while True:\n",
        "  try:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\",\"exit\",\"q\"]:\n",
        "      print(\"Good bye!\")\n",
        "      break\n",
        "    stream_graph_updates(user_input)\n",
        "  except:\n",
        "    # fallback if input is not available\n",
        "    user_input = \"What do you know about LangGraph?\"\n",
        "    print(\"User: \"+ user_input)\n",
        "    stream_graph_updates(user_input)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZrvuvJh3Ywb",
        "outputId": "921ec4f9-3f5b-4be1-f838-dea77a8cae6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Hey\n",
            "Assistant Hey there! What can I do for you today? \n",
            "\n",
            "User: I am Abdul Qadir.\n",
            "Assistant Nice to meet you, Abdul Qadir! Is there anything I can help you with today? \n",
            "\n",
            "User: Can you tell me about unconcious mind.\n",
            "Assistant ## The Unconscious Mind: A Deep Dive\n",
            "\n",
            "The unconscious mind is a fascinating and complex concept that has captivated philosophers and psychologists for centuries. While we can't directly observe it, its influence on our thoughts, feelings, and actions is undeniable. \n",
            "\n",
            "Here's a breakdown of key aspects:\n",
            "\n",
            "**What is the Unconscious Mind?**\n",
            "\n",
            "* **The Hidden Realm:** It refers to the part of our mind that operates outside our conscious awareness. It's a vast reservoir of thoughts, feelings, memories, and impulses that we are not directly aware of.\n",
            "* **Beyond Conscious Control:** We have little to no conscious control over this realm. It processes information and influences our behavior without our conscious knowledge.\n",
            "* **A Powerful Influence:** Despite being hidden, the unconscious mind plays a significant role in shaping our personality, motivations, and decisions.\n",
            "\n",
            "**Key Functions of the Unconscious Mind:**\n",
            "\n",
            "* **Emotional Regulation:** It helps us manage our emotions, often in ways we're not aware of.\n",
            "* **Memory Storage:** It stores memories, both conscious and repressed.\n",
            "* **Motivation and Drive:** It houses our basic instincts and drives, such as hunger, thirst, and the need for safety.\n",
            "* **Defense Mechanisms:** It uses defense mechanisms like repression, denial, and projection to protect us from anxiety and emotional distress.\n",
            "* **Creativity and Intuition:** It can be a source of creativity and intuition, providing insights and solutions we might not have reached consciously.\n",
            "\n",
            "**How the Unconscious Mind Works:**\n",
            "\n",
            "* **Freud's Psychoanalytic Perspective:** Sigmund Freud, the father of psychoanalysis, believed the unconscious mind was a powerful force shaped by early childhood experiences and repressed desires. He proposed the \"id,\" \"ego,\" and \"superego\" as key components of the unconscious.\n",
            "* **Modern Perspectives:** Contemporary psychologists have expanded on Freud's theories, exploring the unconscious through various lenses like cognitive science, neuroscience, and evolutionary psychology.\n",
            "* **The Role of the Brain:** Recent research suggests that the unconscious mind is closely tied to specific brain regions and processes, like the amygdala (emotions) and the hippocampus (memory).\n",
            "\n",
            "**Accessing the Unconscious:**\n",
            "\n",
            "While we can't directly access the unconscious mind, various techniques can help us explore its influence:\n",
            "\n",
            "* **Dreams:** Dreams are often seen as a window into the unconscious, revealing hidden desires, fears, and anxieties.\n",
            "* **Psychotherapy:** Psychoanalysis and other forms of psychotherapy aim to uncover unconscious conflicts and patterns that may be affecting our lives.\n",
            "* **Hypnosis:** Hypnosis can induce a state of deep relaxation and suggestibility, potentially allowing access to unconscious memories and emotions.\n",
            "\n",
            "**Understanding the Unconscious:**\n",
            "\n",
            "Exploring the unconscious mind is a journey of self-discovery. By understanding its influence, we can gain a deeper understanding of our own motivations, behaviors, and emotions. This knowledge can empower us to make healthier choices and live more fulfilling lives.\n",
            "\n",
            "**Important Note:** This is a simplified overview of a complex topic. The unconscious mind is a vast and multifaceted area of study, and there are many different theories and perspectives. It's important to approach this topic with an open mind and to learn from various sources to gain a more comprehensive understanding. \n",
            "\n",
            "User: exit\n",
            "Good bye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Congratulations!** You've built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a [LangSmith Trace](https://smith.langchain.com/public/7527e308-9502-4894-b347-f34385740d5a/r) for the call above at the provided link.\n",
        "\n",
        "However, you may have noticed that the bot's knowledge is limited to what's in its training data. In the next part, we'll add a web search tool to expand the bot's knowledge and make it more capable.\n",
        "\n",
        "Below is the full code for this section for your reference:\n",
        "\n",
        "<details>\n",
        "<summary>Full Code</summary>\n",
        "    <pre>\n",
        "        \n",
        "```python\n",
        "from typing import Annotated\n",
        "\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# The first argument is the unique node name\n",
        "# The second argument is the function or object that will be called whenever\n",
        "# the node is used.\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "graph = graph_builder.compile()\n",
        "```\n",
        "\n",
        "</pre>\n",
        "</details>"
      ],
      "metadata": {
        "id": "-CupGZevBQhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Enhancing the Chatbot with Tools\n",
        "\n",
        "To handle queries our chatbot can't answer \"from memory\", we'll integrate a web search tool. Our bot can use this tool to find relevant information and provide better responses.\n",
        "\n",
        "#### Requirements\n",
        "\n",
        "Before we start, make sure you have the necessary packages installed and API keys set up:\n",
        "\n",
        "First, install the requirements to use the [Tavily Search Engine](https://python.langchain.com/docs/integrations/tools/tavily_search/), and set your [TAVILY_API_KEY](https://tavily.com/)."
      ],
      "metadata": {
        "id": "YVCAtgewBkWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U tavily-python langchain_community"
      ],
      "metadata": {
        "id": "j-eLkrRh2XvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "id": "beTtst4wZfFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next define the tools"
      ],
      "metadata": {
        "id": "l_BGVqqm4acF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "tool.invoke(\"Whats the weather in Lahore Today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WLFfFz5ZfA_",
        "outputId": "c4f91385-25af-44f4-e0f5-f3b84670b571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://www.timeanddate.com/weather/pakistan/lahore/ext',\n",
              "  'content': 'Lahore 14 Day Extended Forecast. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 70 Â°F. Fog. (Weather station: Lahore Airport, Pakistan). See more current weather.'},\n",
              " {'url': 'https://www.accuweather.com/en/pk/lahore/260622/weather-today/260622',\n",
              "  'content': \"Everything you need to know about today's weather in Lahore, Punjab, Pakistan. High/Low, Precipitation Chances, Sunrise/Sunset, and today's Temperature History.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results are page summaries our chat bot can use to answer questions.\n",
        "\n",
        "\n",
        "Next, we'll start defining our graph. The following is all **the same as in Part 1**, except we have added `bind_tools` on our LLM. This lets the LLM know the correct JSON format to use if it wants to use our search engine."
      ],
      "metadata": {
        "id": "-Ml4qKhx_Dku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "def State(TypedDict):\n",
        "  messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def chatbot(state: State):\n",
        "  return {\"messages\": llm_with_tools.invoke((state[\"messages\"]))}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\",chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkCbkPl65t3u",
        "outputId": "76a113be-3ad8-48a9-e3c7-4c8d23050da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langgraph/graph/state.py:64: UserWarning: Invalid state_schema: <function State at 0x7d9047ab4af0>. Expected a type or Annotated[type, reducer]. Please provide a valid schema to ensure correct updates.\n",
            " See: https://langchain-ai.github.io/langgraph/reference/graphs/#stategraph\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d9047fb52d0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we need to create a function to actually run the tools if they are called. We'll do this by adding the tools to a new node.\n",
        "\n",
        "Below, we implement a `BasicToolNode` that checks the most recent message in the state and calls tools if the message contains `tool_calls`. It relies on the LLM's `tool_calling` support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\n",
        "\n",
        "We will later replace this with LangGraph's prebuilt [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode) to speed things up, but building it ourselves first is instructive."
      ],
      "metadata": {
        "id": "ABFbnXVun9MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools_by_name = {tool.name: tool for tool in tools}\n",
        "print(type(tools_by_name))\n",
        "print(tools_by_name)\n",
        "\n",
        "tools_by_name[\"tavily_search_results_json\"]\n",
        "\n",
        "llm_with_tools.invoke(\"Who won in the 2024 Presidential elections?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC1QQo_uE23n",
        "outputId": "f184aa70-f65e-4838-e885-7a289607ecff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "{'tavily_search_results_json': TavilySearchResults(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"2024 Presidential elections\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-d6ccf677-56ba-4352-bcdb-fc68e3ff7052-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '2024 Presidential elections'}, 'id': 'd98ad2b6-83a6-4bec-8c92-40d3ec75dcc2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 86, 'output_tokens': 25, 'total_tokens': 111, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x056L8svpqRV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}